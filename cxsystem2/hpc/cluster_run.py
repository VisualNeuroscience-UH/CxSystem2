#! /usr/bin/env python# -*- coding: utf-8 -*-__author__ = 'Andalibi, V., Hokkanen H., Vanni, S.''''The preliminary version of this software has been developed at Aalto University 2012-2015, and the full version at the University of Helsinki 2013-2017. The software is distributed under the terms of the GNU General Public License. Copyright 2017 Vafa Andalibi, Henri Hokkanen and Simo Vanni.'''import getpassimport osimport pickle as pickleimport socketimport timefrom builtins import inputfrom pathlib import Pathfrom sys import platformimport paramikofrom ping3 import pingfrom scp import SCPClientfrom cxsystem2.configuration import config_file_converter as fileconverterfrom cxsystem2.core.exceptions import ParameterNotFoundError, ClusterNotReachableError, RelativePathErrorfrom cxsystem2.core.tools import parameter_finder, change_parameter_value_in_fileclass ClusterRun:    def __init__(self,                 array_run_obj,                 anat_file_path,                 physio_file_path,                 suffix=""):        time.sleep(20)        try:            self.cluster_workspace = Path(parameter_finder(array_run_obj.anatomy_df, 'cluster_workspace'))        except NameError:            raise ParameterNotFoundError("cluster_workspace is not defined for running CxSystem on cluster")        assert self.cluster_workspace.is_absolute(), \            "cluster_workspace {} must be an absolute path with explicit [remote] home directory path".format(self.cluster_workspace.as_posix())        try:            self.cluster_address = parameter_finder(array_run_obj.anatomy_df, 'cluster_address')        except NameError:            raise ParameterNotFoundError("cluster_address is not defined for running CxSystem on cluster")        try:            self.cluster_login_node = parameter_finder(array_run_obj.anatomy_df, 'cluster_login_node')        except NameError:            print(" -  No cluster login node found. Directly conencting to cluster address {}".format(self.cluster_address))            self.cluster_login_node = '--'        # # the following call will check if the cluster is available or not, but it needs root access        # self.ping_cluster()        try:            self.cluster_username = parameter_finder(array_run_obj.anatomy_df, 'cluster_username')            assert self.cluster_username != 'username', \                "Cluster username must be changed in the configuration file, currently it is the default value 'username'"            print(" -  Loggin in with user '%s'" % self.cluster_username)        except NameError:            self.cluster_username = input(' -  Enter cluster username: ')        try:            self.password = parameter_finder(array_run_obj.anatomy_df, 'password')        except NameError:            if 'CLUSTERPASS' in os.environ.keys():                self.password = os.environ['CLUSTERPASS']            else:                self.password = getpass.getpass(' -  Enter password for user {}: '                                                ''.format(self.cluster_username))        self.suffix = suffix        print(" -  temp file suffix is %s" % self.suffix)        self.client = paramiko.SSHClient()        self.client.load_system_host_keys()        self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())        if self.cluster_login_node != '--':            print(" -  Connecting to login node {}".format(self.cluster_login_node))            sock = paramiko.ProxyCommand("ssh {}@{} nc {} 22".format(self.cluster_username,                                                                     self.cluster_login_node,                                                                     self.cluster_address))            sock.settimeout(30)            self.client.connect(self.cluster_address,                                port=22,                                username=self.cluster_username,                                password=self.password,                                sock=sock)        else:            self.client.connect(self.cluster_address,                                port=22,                                username=self.cluster_username,                                password=self.password)        print(" -  Connected to %s" % self.cluster_address)        print(" -  Creating workspace folder if not exists")        self.ssh_commander('mkdir -p {}'.format(self.cluster_workspace.as_posix()))        scp = SCPClient(self.client.get_transport())        if 'json' in anat_file_path.suffix.lower():            converter = fileconverter.ConfigConverter(anat_file_path.as_posix())            anat_file_path = Path(converter.save_as_csv(overwrite=True))        if 'json' in physio_file_path.suffix.lower():            converter = fileconverter.ConfigConverter(physio_file_path.as_posix())            physio_file_path = Path(converter.save_as_csv(overwrite=True))        print(" -  Transferring configuration files ...")        self.remote_anat_filename = '_tmp_anat_config{}.csv'.format(self.suffix)        self.remote_phys_filename = '_tmp_physio_config{}.csv'.format(self.suffix)        self.local_workspace_unexpanded = Path(parameter_finder(array_run_obj.anatomy_df, 'workspace_path'))        self.local_workspace = Path(parameter_finder(array_run_obj.anatomy_df, 'workspace_path')).expanduser()        self.local_cluster_folder = self.local_workspace.joinpath('cluster_run' + self.suffix)        if not self.local_cluster_folder.is_dir():            os.mkdir(self.local_cluster_folder.as_posix())        try:            imported_connections_file = Path(parameter_finder(array_run_obj.anatomy_df, 'import_connections_from'))            if imported_connections_file.is_file():                scp.put(imported_connections_file.as_posix(), self.cluster_workspace.as_posix())                new_path = Path('./').joinpath(imported_connections_file.name).as_posix()                change_parameter_value_in_file(anat_file_path.as_posix(), self.local_cluster_folder.joinpath(anat_file_path.name),                                               'import_connections_from', new_path)                anat_file_path = self.local_cluster_folder.joinpath(anat_file_path.name)        except TypeError:  # this is when the value is # or -- for instance            pass        scp.put(anat_file_path.as_posix(), self.cluster_workspace.joinpath(self.remote_anat_filename).as_posix())        scp.put(physio_file_path.as_posix(), self.cluster_workspace.joinpath(self.remote_phys_filename).as_posix())        # ask user to set the number of nodes, time and memory:        print(" -  Please check the default csc_taito.job file and set the time, memory and uncomment and enter email address if you wish."              "\nNote that the number of nodes in default slurm file should always be set to 1."              " Instead you should enter the number of nodes in the CxSystem network config file. "              "\nAlso the default number of CPUs=16 does not need to be changed most of the times. ")        self.slurm_file_path = Path(parameter_finder(array_run_obj.anatomy_df, 'cluster_job_file_path')).expanduser()        if not self.slurm_file_path.is_file():            if not self.slurm_file_path.is_absolute():                raise RelativePathError("\nSlurm file {} not found. make sure the path to the file is "                                        "absolute".format(self.slurm_file_path.as_posix()))            else:                raise FileNotFoundError("\nSlurm file {} not found".format(self.slurm_file_path.as_posix()))        # updating remote cxsystem2        self.update_remote_cxsystem2(self.slurm_file_path, self.cluster_workspace)        # building slurm :        for item_idx, item in enumerate(array_run_obj.clipping_indices):            with open(self.slurm_file_path.as_posix(), 'r') as sl1:                remote_slurm_filename = "_tmp_slurm{}_part{}.job".format(self.suffix, item_idx)                with open(self.local_cluster_folder.joinpath(remote_slurm_filename).as_posix(), 'w') as sl2:  # wb -> w                    for line in sl1:                        sl2.write(line)                    try:                        sl2.write("python -c "                                  "\"from cxsystem2.core.cxsystem import CxSystem as cxs; "                                  " cx = cxs('{anatomy}','{physio}', cluster_run_start_idx={cluster_start},cluster_run_step={cluster_step}); "                                  "cx.run()\"".format(anatomy=self.remote_anat_filename,                                                      physio=self.remote_phys_filename,                                                      cluster_start=item,                                                      cluster_step=array_run_obj.clipping_indices[item_idx + 1] - array_run_obj.clipping_indices[                                                          item_idx]))                    except IndexError:                        sl2.write("python -c "                                  "\"from cxsystem2.core.cxsystem import CxSystem as cxs; "                                  " cx = cxs('{anatomy}','{physio}', cluster_run_start_idx={cluster_start},cluster_run_step={cluster_step}); "                                  "cx.run()\"".format(anatomy=self.remote_anat_filename,                                                      physio=self.remote_phys_filename,                                                      cluster_start=item,                                                      cluster_step=array_run_obj.total_configs - array_run_obj.clipping_indices[item_idx]))            scp.put(self.local_cluster_folder.joinpath(remote_slurm_filename).as_posix(),                    self.cluster_workspace.joinpath(remote_slurm_filename).as_posix())        print(" -  Slurm file generated and copied to cluster")        self.channel = self.client.invoke_shell()        self.channel.send('cd %s\n' % self.cluster_workspace.as_posix())        for item_idx, item in enumerate(array_run_obj.clipping_indices):            remote_slurm_filename = "_tmp_slurm{}_part{}.job".format(self.suffix, item_idx)            if platform == 'win32':                print(" -  Converting the file using dos2unix")                self.channel.send('dos2unix {}\n'.format(remote_slurm_filename))                time.sleep(1)            self.channel.send('sbatch {}\n'.format(remote_slurm_filename))            time.sleep(1)        print(" -  Slurm job successfully submitted")        cluster_metadata = \            {'cluster_address': self.cluster_address,             'cluster_login_node': self.cluster_login_node,             'cluster_username': self.cluster_username,             'local_workspace_unexpanded': self.local_workspace_unexpanded.as_posix(),             'local_workspace': self.local_workspace.as_posix(),             'local_cluster_run_folder': self.local_cluster_folder.as_posix(),             'local_cluster_run_download_folder': self.local_cluster_folder.joinpath('downloads'),             'cluster_workspace': self.cluster_workspace.as_posix(),             'cluster_simulation_folder': self.cluster_workspace.joinpath(parameter_finder(array_run_obj.anatomy_df, 'simulation_title')).as_posix(),             'suffix': self.suffix}        with open(self.local_cluster_folder.joinpath('cluster_metadata{}.pkl'.format(self.suffix)), 'wb') as ff:            pickle.dump(cluster_metadata, ff)        print(" -  Cluster metadata saved. To download the result and clean the environments after getting the email,"              " run the following command in the terminal:\n")        print("cxcluster " + self.local_cluster_folder.joinpath('cluster_metadata{}.pkl'.format(self.suffix)).as_posix())    def ping_cluster(self):        try:  # check if the cluster address is ip or hostname            socket.inet_aton(self.cluster_address)            cluster_ip = self.cluster_address        except OSError:            cluster_ip = socket.gethostbyname(self.cluster_address)        p = ping(cluster_ip, timeout=3)        if not p:            raise ClusterNotReachableError("Cluster node is not reachable")    def ssh_commander(self,                      command,                      print_flag=False):        stdin, stdout, stderr = self.client.exec_command(command, get_pty=True)        out = stdout.read(),        if print_flag is True:            print(out[0])        return out[0]    def update_remote_cxsystem2(self,                                slurm_path,                                remote_workspace):        slurm_path = Path(slurm_path)        remote_workspace = Path(remote_workspace)        module_name = self.find_remote_python_module(slurm_path)        self.ssh_commander('mkdir -p {}'.format(self.cluster_workspace.as_posix()))        print(" -  Updating CxSystem2 on cluster")        print(self.ssh_commander('source ~/.bash_profile ; '                                 'cd {workspace} ; '                                 'git clone https://github.com/VisualNeuroscience-UH/CxSystem2 ; '                                 'cd CxSystem2 ; '                                 'git pull ; '.format(workspace=remote_workspace.as_posix())).decode('utf-8'))        print(self.ssh_commander('source ~/.bash_profile ; '                                 'module load {module} ;'                                 'cd {cxfolder} ; '                                 'python -m pip install -r requirements.txt --user ; '                                 'python -m pip install -e . --user'                                 .format(module=module_name, cxfolder=remote_workspace.joinpath('CxSystem2').as_posix())).decode('utf-8'))    def find_remote_python_module(self,                                  slurm_path):        module_name = ''        slurm_path = Path(slurm_path)        with open(slurm_path.as_posix()) as f:            for line in f:                if 'module load' in line.lower() and 'python' in line.lower():                    module_name = line.split(' ')[-1].strip('\n')        print(" -  Remote module name is {}".format(module_name))        return module_nameclass ClusterDownloader:    def __init__(self, metapath, clean_remote=False, retreive=True):        self.metadata_path = Path(metapath)        if not self.metadata_path.is_file():            raise FileNotFoundError("Cluster run metadata file not found: {}".format(self.metadata_path.as_posix()))        self.metadata = self.load_metadata()        self.client = paramiko.SSHClient()        self.client.load_system_host_keys()        self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())        if 'CLUSTERPASS' in os.environ.keys():            self.password = os.environ['CLUSTERPASS']        else:            self.password = getpass.getpass('Enter password for user {}: '.format(self.metadata['cluster_username']))        if self.metadata['cluster_login_node'] != '--':            print(" -  Connecting to login node {}".format(self.metadata['cluster_login_node']))            sock = paramiko.ProxyCommand("ssh {}@{} nc {} 22".format(self.metadata['cluster_username'],                                                                     self.metadata['cluster_login_node'],                                                                     self.metadata['cluster_address']))            sock.settimeout(30)            self.client.connect(self.metadata['cluster_address'],                                port=22,                                username=self.metadata['cluster_username'],                                password=self.password,                                sock=sock)        else:            self.client.connect(self.metadata['cluster_address'],                                port=22,                                username=self.metadata['cluster_username'],                                password=self.password)        self.scpclient = SCPClient(self.client.get_transport())        time.sleep(1)        if not Path(self.metadata['local_workspace']).is_dir():            os.mkdir(self.metadata['local_workspace'])        if retreive:            self.retrieve()        if clean_remote:            self.clean_remote()        self.client.close()    @staticmethod    def ssh_commander(client,                      command,                      print_flag):        stdin, stdout, stderr = client.exec_command(command)        out = stdout.read(),        if print_flag:            print(out[0])        return out[0]    def load_metadata(self):        with open(self.metadata_path.as_posix(), 'rb') as f:            return pickle.load(f)    def retrieve(self):        waiting_flag = True        print(" -  Waiting for the results ...")        if not self.metadata['local_cluster_run_download_folder'].is_dir():            os.mkdir(self.metadata['local_cluster_run_download_folder'].as_posix())        while waiting_flag:            # if not ssh_commander(client,'cd %s; ls -d */' % (remote_result_abs_path), 0) and \            # 'metadata' in ssh_commander(client,'cd %s; ls' % (remote_result_abs_path), 0):            # just a better check:            if not self.metadata['cluster_username'] in self.ssh_commander(self.client, 'squeue -l -u {}'.format(self.metadata['cluster_username']),                                                                           0).decode('utf-8'):                # here it means there is no folder in result folder and therefore all simulations are done                # so we copy back the result and remove the files on cluster                print(" -  Downloading the results from cluster...")                for item in self.ssh_commander(self.client, 'cd {}; ls'.format(self.metadata['cluster_simulation_folder']), 0).decode('utf-8').split(                        '\n'):                    if item != '' and self.metadata['suffix'] in item:                        self.scpclient.get(Path(self.metadata['cluster_simulation_folder']).joinpath(item).as_posix(),                                           Path(self.metadata['local_cluster_run_download_folder']).joinpath(item).as_posix())                        print('\t', item)                # cleaning                # self.ssh_commander(self.client, 'rm -rf {}'.format(self.metadata['cluster_workspace']), 0)                waiting_flag = False            time.sleep(1)        print(" -  Downloads are available in: {}".format(self.metadata['local_cluster_run_download_folder']))    def clean_remote(self):        self.ssh_commander(self.client,                           'rm -rf {}'.format(self.metadata['cluster_workspace']), 0).decode('utf-8').split('\n')        self.ssh_commander(self.client,                           'rm -rf {}'.format(self.metadata['local_workspace_unexpanded']), 0).decode('utf-8').split('\n')        print(" -  Results are downloaded and remote is cleaned.")if __name__ == '__main__':    cl = ClusterDownloader('/home/corriel/CxPytestWorkspace/cluster_run_20191127_1223593/cluster_metadata_20191127_1223593.pkl', retreive=False)    cl.clean_remote()